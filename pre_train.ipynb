{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import subprocess\n",
    "from natsort import natsorted\n",
    "import pickle\n",
    "from InterfaceDeclaration import LPBFData\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  \n",
    "sys.path.append(\"./utls\")\n",
    "sys.path.append(\"./models\")\n",
    "import os\n",
    "from MLUtls import LPBFDataset, get_max_length, transform_pad, fade_in_out\n",
    "\n",
    "project_name = [\"MuSIC\", \"MaPS\", \"MuSIC_EXP1\"]\n",
    "if os.name == \"posix\":\n",
    "    data_dir = subprocess.getoutput(\"echo $DATADIR\")\n",
    "elif os.name == \"nt\":\n",
    "    data_dir = subprocess.getoutput(\"echo %datadir%\")\n",
    "music_dir = os.path.join(data_dir, \"MuSIC\")\n",
    "if not os.path.exists(music_dir):\n",
    "    project_name[0] = \"2024-MUSIC\"\n",
    "daq_dir = os.path.join(data_dir, *project_name, \"Acoustic Monitoring\")\n",
    "lmq_dir = os.path.join(data_dir, *project_name, \"LMQ Monitoring\")\n",
    "del music_dir\n",
    "\n",
    "with open(os.path.join(os.path.dirname(daq_dir),'intermediate',f\"lpbf_line_wise_data.pkl\"), 'rb') as handle:\n",
    "    lpbf_data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_speed = LabelEncoder().fit(np.asarray(lpbf_data.scanning_speed,dtype=str))\n",
    "le_region = LabelEncoder().fit(np.asarray(lpbf_data.regime_info,dtype=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_power = StandardScaler().fit(np.unique(lpbf_data.laser_power).astype(float).reshape(-1,1))\n",
    "sc_direction = StandardScaler().fit(np.unique(lpbf_data.print_vector[1]).astype(float).reshape(-1,1))\n",
    "le_speed = LabelEncoder().fit(np.asarray(lpbf_data.scanning_speed,dtype=str))\n",
    "le_region = LabelEncoder().fit(np.asarray(lpbf_data.regime_info,dtype=str))\n",
    "\n",
    "laser_power = sc_power.transform(np.asarray(lpbf_data.laser_power).astype(float).reshape(-1,1)).reshape(-1)\n",
    "print_direction = sc_direction.transform(np.asarray(lpbf_data.print_vector[1]).astype(float).reshape(-1,1)).reshape(-1)\n",
    "scanning_speed = le_speed.transform(np.asarray(lpbf_data.scanning_speed).astype(float))\n",
    "regime_info = le_region.transform(np.asarray(lpbf_data.regime_info,dtype=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = \"mic+direction\".split(\"+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(lpbf_data.cube_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MLUtls import LPBFDataset,  transform_pad, fade_in_out,transform_ft, standardize_tensor\n",
    "from models.MLModels import CNN_Base_1D_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LPBFDataset(lpbf_data.cube_position,laser_power,lpbf_data.scanning_speed,regime_info,print_direction,lpbf_data.microphone, lpbf_data.AE, lpbf_data.defect_labels)\n",
    "dataloader = DataLoader(dataset,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_list = []\n",
    "_cube_position, _laser_power, _scanning_speed, _regime_info, _print_direction, _microphone, _ae, _defect_labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = (transform_ft()(standardize_tensor(_microphone))).double()\n",
    "meta_list.append(_print_direction.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_length = 5880\n",
    "meta_data_size = len(meta_list)\n",
    "time_series_length+meta_data_size\n",
    "model = CNN_Base_1D_Model(time_series_length=time_series_length,meta_data_size=meta_data_size,num_classes=4).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4941, 0.5422, 0.5362, 0.5286],\n",
       "        [0.4559, 0.5562, 0.5245, 0.5188],\n",
       "        [0.4835, 0.5458, 0.5489, 0.5305],\n",
       "        [0.4937, 0.5521, 0.5418, 0.5272],\n",
       "        [0.4920, 0.5468, 0.5112, 0.5099],\n",
       "        [0.4927, 0.5328, 0.5176, 0.5262],\n",
       "        [0.4875, 0.5386, 0.5324, 0.5279],\n",
       "        [0.4971, 0.5422, 0.5298, 0.5208]], dtype=torch.float64,\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(time_series,meta_list)\n",
    "probs = torch.sigmoid(logits)\n",
    "predictions = torch.argmax(probs,axis=1).clone().int().detach().cpu()\n",
    "predictions == _regime_info\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.MLUtls import fade_in_out, standardize_tensor, CylinderDataset,LCVDataset, getKFoldCrossValidationIndexes, train_log, transform_ft, dataset_by_cross_validation, labels_by_classes, get_current_fold_and_hist, LPBFDataset\n",
    "folds = getKFoldCrossValidationIndexes(10000, 10, seed=10086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = folds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
